{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79fcddf3",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "* [Repositorio de Pandas](https://github.com/pandas-dev/pandas)\n",
    "* [Documentación Oficial](https://pandas.pydata.org/)\n",
    "\n",
    "***\n",
    "\n",
    "**Pandas** es una herramienta/*framework* esencial para trabajar con datos tabulares y series temporales. Su utilidad radica en su capacidad para manipular y analizar datos de manera eficiente, facilitando las tareas comunes en el análisis de datos, como la limpieza, la transformación y la visualización.\n",
    "\n",
    "### Principales estructuras de datos proporcionadas por Pandas\n",
    "\n",
    "* **Series**: Una estructura unidimensional que puede albergar cualquier tipo de datos y está etiquetada, facilitando el acceso a los datos mediante etiquetas.\n",
    "\n",
    "* **DataFrame**: Una estructura de datos bidimensional similar a una hoja de cálculo con etiquetas de fila y columna, que permite almacenar y manipular datos de manera eficiente.\n",
    "\n",
    "### Beneficios de usar Pandas\n",
    "* Manipulación de datos eficiente: Pandas proporciona métodos y funciones optimizados para la manipulación de datos, como la limpieza, la filtración, la agregación y la transformación.\n",
    "\n",
    "* Manejo de datos faltantes: Pandas facilita el manejo de valores nulos o faltantes en los conjuntos de datos, permitiendo su identificación y tratamiento de manera sencilla.\n",
    "\n",
    "* Integración con otras bibliotecas: Se integra fácilmente con otras bibliotecas populares de Python, como NumPy, Matplotlib y scikit-learn, proporcionando un entorno completo para el análisis de datos.\n",
    "\n",
    "* Operaciones de series temporales: Ofrece funciones avanzadas para trabajar con datos de series temporales, como la resampling y la interpolación.\n",
    "\n",
    "* Entrada y salida de datos: Permite la lectura y escritura de datos en varios formatos, incluyendo CSV, Excel, SQL, y más, facilitando la interoperabilidad con otras herramientas y sistemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7a7785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# por convensión, se importa bajo el siguiente nombre\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48eb3aa",
   "metadata": {},
   "source": [
    "***\n",
    "## Series (*pd.Series*)\n",
    "\n",
    "[Documentación de pd.Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html#pandas.Series)\n",
    "\n",
    "Una pd.Series es una estructura de datos unidimensional que puede almacenar cualquier tipo de datos, como números enteros, números de punto flotante, cadenas, objetos de Python, entre otros. La pd.Series se puede ver como una columna en una hoja de cálculo o una columna en una tabla de base de datos.\n",
    "\n",
    "#### Algunas características:\n",
    "1. Índice: Cada elemento en una Series está asociado a un índice. El índice puede ser automático (números enteros por defecto) o personalizado, lo que permite un acceso más fácil y eficiente a los datos.\n",
    "\n",
    "1. Datos: La Series almacena los datos como un arreglo unidimensional. Puedes acceder a estos datos mediante el índice.\n",
    "\n",
    "1. Etiquetas: Puedes asignar etiquetas a la Series para identificar más fácilmente sus componentes. Esto facilita el acceso y manipulación de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e606d",
   "metadata": {},
   "source": [
    "### Crear una pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5a130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para crear una serie se requiere de un conjunto de datos unidimensionales\n",
    "\n",
    "data = [1,2,3,4,5,6]\n",
    "\n",
    "serie = pd.Series(data)\n",
    "\n",
    "print(serie)\n",
    "print('Es una pd.Series -->', type(serie))\n",
    "# como se puede ver, la serie posee dos columnas. La columna ubicada a la izquierda representa el index de la pd.Series; mientras que la restante, los valores de la serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c339ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# al crear la pd.Series se puede, además, definir el índice (index) de la misma\n",
    "\n",
    "data = range(10)\n",
    "idx = [f'idx_{i}' for i in range(10)]\n",
    "\n",
    "print(pd.Series(data, index=idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68437d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# las pd.Series también pueden ser creadas a partir de un dict\n",
    "\n",
    "d = {'id0': 0, 'id1': 1, 'id2': 2}\n",
    "\n",
    "print(pd.Series(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89119464",
   "metadata": {},
   "source": [
    "### Características de la pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f0848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# es posible obtener cierta información de la serie bajo análisis\n",
    "\n",
    "serie_1 = pd.Series([1,2,3,4,5,6])\n",
    "serie_2 = pd.Series([0.5, 1.0, 1.5, 2.0, 2.5])\n",
    "serie_3 = pd.Series(['a', 'b', 'c', 'd'])\n",
    "\n",
    "# tamaño de la misma\n",
    "print('La serie_1 posee {} elementos, y sus datos son del tipo {}.'.format(serie_1.shape[0], serie_1.dtypes))\n",
    "print('La serie_2 posee {} elementos, y sus datos son del tipo {}.'.format(serie_2.shape[0], serie_2.dtypes))\n",
    "print('La serie_3 posee {} elementos, y sus datos son del tipo {}.'.format(serie_3.shape[0], serie_3.dtypes))\n",
    "\n",
    "# algo equivalente se puede obtener usando el método 'size'\n",
    "print('Tamanño serie 1: {}.'.format(serie_1.size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c3c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# es posible analizar si la serie posee valores nulos\n",
    "\n",
    "serie_1 = pd.Series([1,2,3,4,5,6])\n",
    "serie_2 = pd.Series([1,2,None,4,5,None])\n",
    "\n",
    "# alternativa 1: revisar en forma general si dicha serie posee valores nulos. En caso de que exista al menos uno, devuelve True.\n",
    "print('La serie 1 posee nulos?', serie_1.hasnans)\n",
    "print('La serie 2 posee nulos?', serie_2.hasnans)\n",
    "\n",
    "# alternativa 2: revisar elemento a elemento y devolver un valor True/False en cada posición de la serie\n",
    "\n",
    "print('Elementos nulos en la serie 1', serie_1.isna(), sep='\\n')\n",
    "print('Elementos nulos en la serie 2', serie_2.isna(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117ae144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cantidad de elementos únicos en la series y cantidad de cada tipo de elemento\n",
    "data = ['auto'] * 10 + ['moto'] * 12 + ['camion'] * 3\n",
    "serie = pd.Series(data)\n",
    "\n",
    "print(f'La serie posee {serie.nunique()} elementos únicos.', f'Los valores únicos son {serie.unique()}.', f'Y se distribuyen de la siguiente forma:', serie.value_counts(normalize=True), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e89c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para visualizar la serie en forma parcial, se usa el método 'head' o 'tail'\n",
    "\n",
    "print(serie.head(5))\n",
    "print(serie.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d861b6",
   "metadata": {},
   "source": [
    "***\n",
    "### Operaciones con pd.Series\n",
    "\n",
    "1. Operaciones matemáticas (vectoriales)\n",
    "1. Operaciones estadísticas\n",
    "1. Comparaciones lógicas\n",
    "1. Filtrado y Slicing\n",
    "1. Interacción con Numpy\n",
    "1. Concatenar\n",
    "1. Relleno de valores faltantes\n",
    "1. Agrupación y operaciones agrupadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be19fb",
   "metadata": {},
   "source": [
    "#### Operaciones matemáticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c8746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Función Auxiliar para generar data #####\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(9999)\n",
    "\n",
    "data_1 = rng.normal(4, 0.5, size=100)\n",
    "data_2 = rng.exponential(2.5, size=100)\n",
    "data_3 = rng.uniform(0, 50, size=100).astype(int)\n",
    "data_4 = rng.uniform(25, 60, size=100).astype(int)\n",
    "\n",
    "serie_1 = pd.Series(data_1)\n",
    "serie_2 = pd.Series(data_2)\n",
    "serie_3 = pd.Series(data_3)\n",
    "serie_4 = pd.Series(data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eda070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suma, resta, multiplicación y división\n",
    "\n",
    "print('Suma')\n",
    "suma = serie_1 + serie_2\n",
    "print(suma.head())\n",
    "\n",
    "print('Resta')\n",
    "resta = serie_1 - serie_2\n",
    "print(resta.head())\n",
    "\n",
    "print('Multiplicación')\n",
    "mult = serie_1 * serie_2\n",
    "print(mult.head())\n",
    "\n",
    "print('División')\n",
    "div = serie_1 / serie_2\n",
    "print(div.head())\n",
    "\n",
    "print('Suma de un escalar')\n",
    "suma_esc = serie_3 + 10\n",
    "print(suma_esc.head())\n",
    "\n",
    "print('Producto de un escalar')\n",
    "mult_esc = serie_3 * 1.75\n",
    "print(mult_esc.head())\n",
    "\n",
    "print('Potencia')\n",
    "pot = serie_2.pow(2) # equivalente a serie_2**2\n",
    "\n",
    "# todas estas operaciones tiene un método de pandas asociado, pero la sintaxis es más compleja y se obtiene el mismo resultado en el mismo tiempo de cómputo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f729d0",
   "metadata": {},
   "source": [
    "#### Operaciones estadísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e39b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# promedio, desvío y percentiles\n",
    "\n",
    "promedio = serie_1.mean()\n",
    "desvio = serie_1.std()\n",
    "perc = serie_1.quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "print(f'Promedio: {round(promedio, 4)}', f'Desvío: {round(desvio, 4)}', 'Percentiles:', perc, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3521b840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# máximo, mínimo, moda, n-mayores y n-menores\n",
    "\n",
    "maximo = serie_4.max()\n",
    "minimo = serie_4.min()\n",
    "moda = serie_4.mode()\n",
    "n_mayores = serie_4.nlargest(5)\n",
    "n_menores = serie_4.nsmallest(5)\n",
    "\n",
    "print(f'Máximo: {maximo}', f'Mínimo: {minimo}', f'Moda: {moda}', 'n_mayores:', n_mayores, 'n_menores', n_menores, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab046747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumsum, pct_change\n",
    "\n",
    "print('Suma acumulada')\n",
    "suma_acumulada = serie_3.cumsum()\n",
    "display(pd.concat([serie_3, suma_acumulada],axis=1).rename(columns={0:'Original', 1:'Suma Acumulada'}).head(10))\n",
    "\n",
    "print('Porcentaje de cambio')\n",
    "pct = serie_4.pct_change() * 100\n",
    "display(pd.concat([serie_4, pct],axis=1).rename(columns={0:'Original', 1:'% Cambio'}).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde7cb0",
   "metadata": {},
   "source": [
    "#### Operaciones lógicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# los elementos de una serie puieden ser comparados contra un valor específico o contra otra serie\n",
    "# es posible utilizar los signos: \">\", \"<\", \">=\", \"<=\", \"==\", \"!=\"\n",
    "# o los métodos: gt, lt, ge, le, eq, ne \n",
    "\n",
    "serie = pd.Series([10, 12, 44, 60, 19, 25, 20])\n",
    "serie_comp = pd.Series([14, 10, 44, 55, 20, 25, 27])\n",
    "k = 20\n",
    "\n",
    "# gt o ge\n",
    "print(serie > k)\n",
    "print(serie.ge(k))\n",
    "print(serie.ge(serie_comp))\n",
    "\n",
    "# lt o le\n",
    "print(serie < k)\n",
    "print(serie.le(k))\n",
    "print(serie.le(serie_comp))\n",
    "\n",
    "# eq o nn\n",
    "print(serie == k)\n",
    "print(serie.ne(k))\n",
    "print(serie.eq(serie_comp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# posible concatenar múltiples operaciones lógicas\n",
    "\n",
    "(serie > 0.75 * k) & (serie < 1.25 * k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437367c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# operador between\n",
    "\n",
    "serie.between(k, 2*k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f72bc8",
   "metadata": {},
   "source": [
    "#### Filtrado y Slicing\n",
    "\n",
    "Todas las operaciones lógicas pueden ser usadas para filtrar o hacer slicing en las pd.Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a1137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# las Series nos permiten filtrar elementos en base a cierta condiciones o condiciones\n",
    "\n",
    "cond_1 = serie_3 > 25\n",
    "serie_filtrada = serie_3[cond_1]\n",
    "\n",
    "print(f'Serie original: {serie_3.size}. Serie filtrada: {serie_filtrada.size}')\n",
    "\n",
    "cond_2 = serie_3 <= 45\n",
    "serie_filtrada_2 = serie_3[cond_1 & cond_2] # & --> 'Y'\n",
    "\n",
    "print(f'Serie original: {serie_3.size}. Serie filtrada: {serie_filtrada_2.size}')\n",
    "\n",
    "cond_3 = (serie_3 < 5) | (serie_3 > 45) # | --> 'O'\n",
    "serie_filtrada_3 = serie_3[cond_3]\n",
    "\n",
    "print(f'Serie original: {serie_3.size}. Serie filtrada: {serie_filtrada_3.size}')\n",
    "\n",
    "### Todas estas operaciones también se pueden realizar usando el método 'loc'. Este método es mayormente usado en los pd.DataFrame's\n",
    "\n",
    "print('Ejemplo usando \"loc\":')\n",
    "cond_1 = serie_3 > 25\n",
    "serie_filtrada = serie_3.loc[cond_1]\n",
    "print(f'Serie original: {serie_3.size}. Serie filtrada: {serie_filtrada.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# otra alternativa es filtrar por el valor del índice (o index). Para ello se usa el método \"iloc\"\n",
    "\n",
    "idx = 26\n",
    "\n",
    "print(f'Me devuelve el elemento ubicado en la posición {idx}:', serie_3.iloc[26])\n",
    "\n",
    "print(f'Me devuelve los elementos ubicados luego de la posición {idx}:', serie_3.iloc[26:])\n",
    "\n",
    "print(f'Me devuelve los elementos ubicados antes de la posición {idx}:', serie_3.iloc[:26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7807783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# otra forma de filtrar es usando el método \"isin()\"\n",
    "\n",
    "cond_isin = serie_3.isin([4, 12, 16, 20, 43])\n",
    "serie_3[cond_isin]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46777a2",
   "metadata": {},
   "source": [
    "#### Interacción con Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f579904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ddae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# las pd.Series pueden ser trasnformadas en un np.array\n",
    "\n",
    "serie = pd.Series([1, 2, 3, 4, 5])\n",
    "print(serie)\n",
    "print(type(serie))\n",
    "\n",
    "array = serie.values\n",
    "print(array)\n",
    "print(type(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbbc86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# las operaciones y funciones de Numpy pueden ser aplicadas directamente a las pd.Series\n",
    "\n",
    "serie = pd.Series(np.arange(1, 25, 1))\n",
    "print(serie.head())\n",
    "\n",
    "# np.where()\n",
    "print('\\nnp.where (1)', np.where(serie > 15, 100, 0), sep = '\\n')\n",
    "\n",
    "print('\\nnp.where (2)', serie[np.where(serie%2 == 0)[0]], sep = '\\n')\n",
    "\n",
    "# np.power()\n",
    "print('\\nnp.power', np.power(serie, 3), sep='\\n')\n",
    "\n",
    "### todas las unfuncs de NumPy pueden aplicadas a las pd.Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bc85a0",
   "metadata": {},
   "source": [
    "#### Concatenar pd.Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77e7620",
   "metadata": {},
   "source": [
    "* Existe la capacidad de *unir* dos o más ```pd.Series``` por medio de la función ```pd.concat```\n",
    "* La operación de *unir* dichas series se conoce como **concatenar**\n",
    "* Puede ser realizada de dos formas:\n",
    "\n",
    "##### Verticalmente: \n",
    "\n",
    "```\n",
    "Serie 1\n",
    "```\n",
    "| Índice | Serie 1 | \n",
    "|--------|---------|\n",
    "| a      | 1       |\n",
    "| b      | 2       |\n",
    "| c      | 3       |\n",
    "```\n",
    "Serie 2\n",
    "```\n",
    "| Índice | Serie 2 |\n",
    "|--------|---------|\n",
    "| d      | 4       |\n",
    "| e      | 5       |\n",
    "\n",
    "```\n",
    "Serie Concatenada\n",
    "```\n",
    "| Índice | Serie Concatenada |\n",
    "|--------|-------------------|\n",
    "| a      | 1                 |\n",
    "| b      | 2                 |\n",
    "| c      | 3                 |\n",
    "| d      | 4                 |\n",
    "| e      | 5                 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_1 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "serie_2 = pd.Series([4, 5], index=['d', 'e'])\n",
    "\n",
    "pd.concat([serie_1, serie_2], axis = 0) # axis = 0 representa 'vertical' o 'columna'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4890ef98",
   "metadata": {},
   "source": [
    "##### Horizontalmente: \n",
    "\n",
    "```\n",
    "Serie 1\n",
    "```\n",
    "| Índice | Serie 1 | \n",
    "|--------|---------|\n",
    "| a      | 1       |\n",
    "| b      | 2       |\n",
    "| c      | 3       |\n",
    "```\n",
    "Serie 2\n",
    "```\n",
    "| Índice | Serie 2 |\n",
    "|--------|---------|\n",
    "| a      | 4       |\n",
    "| b      | 5       |\n",
    "\n",
    "```\n",
    "Serie Concatenada\n",
    "```\n",
    "| Índice | Serie 1 | Serie 2 |\n",
    "|--------|---------|---------|\n",
    "| a      | 1       | 4       |  \n",
    "| b      | 2       | 5       |\n",
    "| c      | 3       | NaN    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# la unión de las filas se realiza a nivel de index, es decir, se concatenan aquellos comn el mismo index\n",
    "serie_1 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "serie_2 = pd.Series([4, 5], index=['a', 'b'])\n",
    "\n",
    "pd.concat([serie_1, serie_2], axis = 1) # axis = 0 representa 'horizontal' o 'fila'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca87c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# si los indexes están repetidos en la misma serie, se produce un error!\n",
    "serie_1 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "serie_2 = pd.Series([4, 5], index=['a', 'a'])\n",
    "\n",
    "try:\n",
    "    pd.concat([serie_1, serie_2], axis = 1) # axis = 0 representa 'horizontal' o 'fila'\n",
    "except ValueError:\n",
    "    print('Se produjo un error!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a066735b",
   "metadata": {},
   "source": [
    "### Llenado de valores faltantes\n",
    "\n",
    "Puede ocurrir que la fuente de datos a usar posean valores nulos (en otras palabras, posiciones en las cuales la serie no posee valor alguno). Para sobrepasar ese problema, se poseen diversas alternativas:\n",
    "* filtrar valores nulos\n",
    "* completar/computar dichas posiciones con determinados valor\n",
    "    * con valor arbitrario (```fillna(n)```)\n",
    "    * con valor estadístico de la serie (```fillna(n_stat)```)\n",
    "    * con valor posterior/anterior (```ffill()```, ```bfill()```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608cb12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Función Auxiliar para generar data #####\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(9999)\n",
    "\n",
    "data = rng.choice(a=[np.nan,0, 10, 20, 30, 40, 50], p=[1/7]*7, size=100)\n",
    "\n",
    "serie = pd.Series(data).astype('Int32')\n",
    "\n",
    "print('Distribución de valores en la serie')\n",
    "serie.value_counts(dropna=False, normalize=True) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de19e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# con valor arbitrario\n",
    "\n",
    "k = 32\n",
    "\n",
    "serie_fillna_k = serie.fillna(k)\n",
    "\n",
    "serie_fillna_k.value_counts(dropna=False, normalize=True) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# con valor estadístico\n",
    "\n",
    "media = int(serie.mean())\n",
    "\n",
    "serie_fillna_mean = serie.fillna(media)\n",
    "\n",
    "serie_fillna_mean.value_counts(dropna=False, normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84a3ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# con valor psoterior o anterior\n",
    "\n",
    "serie_ffill = serie.ffill()\n",
    "print('ffill', serie_ffill.value_counts(dropna=False, normalize=True) * 100, sep='\\n')\n",
    "\n",
    "serie_bfill = serie.bfill()\n",
    "print('\\nbfill', serie_bfill.value_counts(dropna=False, normalize=True) * 100, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Relleno de valores faltantes\n",
    "1. Agrupación y operaciones agrupadas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
