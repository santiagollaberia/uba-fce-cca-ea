{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "* [Repositorio de Pandas](https://github.com/pandas-dev/pandas)\n",
    "* [Documentación Oficial](https://pandas.pydata.org/)\n",
    "\n",
    "***\n",
    "## DataFrame (pd.DataFrame)\n",
    "\n",
    "[Documentación de pd.DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame)\n",
    "\n",
    "**Pandas DataFrame** es una **estructura de datos bidimensional y etiquetada**, diseñada para manejar y analizar datos tabulares en el entorno de programación Python. Su desarrollo se basa en la biblioteca NumPy y proporciona funcionalidades adicionales para facilitar la manipulación y análisis de datos.\n",
    "\n",
    "#### Características Principales:\n",
    "\n",
    "* **Bidimensionalidad**: Un DataFrame consiste en filas y columnas, organizando los datos en una tabla rectangular. Cada columna puede contener diferentes tipos de datos, permitiendo la representación de información heterogénea.\n",
    "\n",
    "* **Etiquetado**: Tanto las filas como las columnas están etiquetadas, lo que facilita el acceso y la manipulación de datos. Los índices y nombres de columnas pueden ser personalizados para reflejar la naturaleza específica de los datos.\n",
    "\n",
    "* **Integración con NumPy**: Se basa en la eficiente biblioteca NumPy, permitiendo operaciones vectorizadas y aprovechando las ventajas de la computación numérica en Python.\n",
    "\n",
    "#### Ventajas de Pandas DataFrame:\n",
    "\n",
    "* **Facilidad de Uso**: Proporciona una interfaz intuitiva y fácil de usar para realizar operaciones complejas en datos tabulares.\n",
    "\n",
    "* **Manejo de Datos Faltantes**: Ofrece herramientas para manejar valores nulos o faltantes de manera eficiente, evitando la pérdida de información durante el análisis.\n",
    "\n",
    "* **Operaciones de Series Temporales**: Incorpora funcionalidades avanzadas para el trabajo con datos de series temporales, facilitando el análisis de tendencias a lo largo del tiempo.\n",
    "\n",
    "* **Entrada y Salida de Datos**: Permite la lectura y escritura de datos en varios formatos, como CSV, Excel, SQL, y más, favoreciendo la interoperabilidad con otras herramientas y sistemas.\n",
    "\n",
    "* **Operaciones de Agrupación y Agregación**: Facilita la agrupación de datos basada en criterios específicos y la aplicación de funciones de agregación para resumir la información.\n",
    "\n",
    "#### Funcionalidades Clave:\n",
    "\n",
    "* **Indexación y Selección Eficiente**: Permite el acceso y manipulación de datos utilizando etiquetas de filas y columnas, así como índices booleanos.\n",
    "\n",
    "* **Operaciones Estadísticas y Matemáticas**: Proporciona métodos integrados para realizar cálculos estadísticos, operaciones matemáticas y transformaciones en los datos.\n",
    "\n",
    "* **Visualización Integrada**: Se integra con bibliotecas de visualización como Matplotlib y Seaborn, facilitando la creación de gráficos y visualizaciones de datos.\n",
    "\n",
    "* **Manipulación de Datos Complejos**: Ofrece funcionalidades para la limpieza, filtración, combinación y transformación de datos complejos, lo que facilita la preparación de datos para el análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agenda**\n",
    "\n",
    "* Creación de pd.DataFrame\n",
    "* Analogía/relación entre pd.DataFrame y pd.Series\n",
    "* Características\n",
    "* Operaciones vectoriales\n",
    "* Operaciones matemáticas\n",
    "* Operaciones estadísticas\n",
    "* Operaciones lógicas\n",
    "* Filtrado y slicing\n",
    "* Interacción con NumPy\n",
    "* Concatenar y Merges\n",
    "* Relleno de valores faltantes\n",
    "* Agrupación y operaciones agrupadas\n",
    "* Leer y guardar pd.DataFrame desde csv, parquet y url."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Crear un pd.DataFrame\n",
    "\n",
    "Existen diversas formas de generar un pd.DataFrame a partir de las siguientes estructuras:\n",
    "1. *dict*\n",
    "1. *pd.Series* (o *list*)\n",
    "1. *np.ndarray*\n",
    "\n",
    "En todas las alternativas se debe usar el constructor de *Pandas*: ```pd.DataFrame(...)```\n",
    "\n",
    "*Existen otras maneras adicionales de hacerlo, pero para el alcance de este curso las que se presentan anteriormente son suficientes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar la librería\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. dict\n",
    "\n",
    "# definir un dict\n",
    "d = {'columna_1': [0,1,2,3,4,5,6,7,8,9], 'columna_2': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]}\n",
    "\n",
    "# por convensión se lo llama \"df\"\n",
    "df = pd.DataFrame(data = d)\n",
    "\n",
    "# \"display\" permite ver el datafgrame (es otra alternativa)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('df es un pd.DataFrame:', type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. pd.Series o lists\n",
    "\n",
    "serie_1 = pd.Series([i**2 for i in range(10)], name='valores_cuadrados')\n",
    "serie_2 = pd.Series([i + 5 for i in range(10)], name= 'valores_mas_5')\n",
    "\n",
    "# usar la función pd.concat (vista en el notebook anterior)\n",
    "df = pd.concat([serie_1, serie_2],axis=1)\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_1 = [i**2 for i in range(10)]\n",
    "lista_2 = [i + 5 for i in range(10)]\n",
    "\n",
    "col_names = ['valores_cuadrados', 'valores_mas_5']\n",
    "\n",
    "# usar la función pd.concat (vista en el notebook anterior)\n",
    "df = pd.concat([serie_1, serie_2],axis=1)\n",
    "\n",
    "# cambiar los nombres ya que las listas NO tienen nombres\n",
    "df.columns = col_names\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. np.ndarray\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# crea el array y camniar el shape a una sola columna\n",
    "array_1d = np.array([range(0, 20, 2)]).reshape((-1,))\n",
    "\n",
    "df = pd.DataFrame(array_1d, columns=['columna 1'])\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_nd = np.random.random(size=(20, 3))\n",
    "\n",
    "df = pd.DataFrame(array_nd, columns=[f'columna {i}' for i in range(array_nd.shape[1])])\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analogía/relación entre pd.DataFrame y pd.Series\n",
    "\n",
    "Es importante resaltar que existe una clara relación entre ```pd.DataFrame``` y ```pd.Series```: un ```pd.DataFrame``` es **un conjunto de** ```pd.Series``` **concatenadas de forma horizontal**.\n",
    "\n",
    "Mediante el uso de *slcing* (visto en el notebook previo y que posteriormente será ampliado en este notebook) se puede demostrar esta afirmación:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'columna_1': [0,1,2,3,4,5,6,7,8,9], 'columna_2': [10,11,12,13,14,15,16,17,18,19]}\n",
    "\n",
    "df = pd.DataFrame(data = d)\n",
    "\n",
    "col_1 = df['columna_1']\n",
    "col_2 = df['columna_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'- df es un {type(df)}', f'col_1 es una {type(col_1)}', f'col_2 es una {type(col_2)}', sep='\\n- ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importante: Esto implica que la gran mayoría de las operaciones que funcionan en las pd.Series con aplicables a los pd.DataFrame!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Características de un pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_int = np.random.choice(a=[10, 20, 30, 40, 50], size=(40, 6))\n",
    "df_int = pd.DataFrame(array_int, columns=[f'columna {i}' for i in range(array_int.shape[1])], dtype=int)\n",
    "\n",
    "array_float = np.random.random(size=(50, 5))\n",
    "df_float = pd.DataFrame(array_float, columns=[f'columna {i}' for i in range(array_float.shape[1])],dtype=float)\n",
    "\n",
    "array_str = np.random.choice(a= ['a', 'b', 'c'], size=(35, 6))\n",
    "df_str = pd.DataFrame(array_str, columns=[f'columna {i}' for i in range(array_str.shape[1])], dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, df in enumerate([df_int, df_float, df_str]):\n",
    "    print('El df #{} posee {} registros y {} columnas.\\nSus datos son del tipo\\n{}\\n'.format(n+1, df.shape[0], df.shape[1], df.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es posible analizar si el df posee valores nulos y ver en qué columnas se encuentran\n",
    "\n",
    "df_nans = pd.DataFrame(np.random.choice(a=[np.nan, 1, 2, 3 ,4, 5], size=(100, 5)), columns=[f'columna_{i}' for i in range(5)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con el método \"isna()\" se puede visualizar, mediante un dataframe de valores booleanos, si el valor de cierta posición es nulo\n",
    "df_nans.isna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se pueden sumar dichas columnas de booleanos y obtener la cantidad de nulos en cada columna\n",
    "df_nans.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y volverlas a sumar para saber la cantidad total de nulos en el dataframe\n",
    "df_nans.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se puede ver el nombre de las columnas\n",
    "df_nans.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cantidad de elementos únicos en cada columna y cantidad de cada tipo de elemento\n",
    "for col in df_str.columns:\n",
    "    print('\\n--', col)\n",
    "    print(df_str[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para visualizar el df en forma parcial, se usa el método 'head' o 'tail'\n",
    "\n",
    "display(df.head(5))\n",
    "display(df.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones vectorizadas\n",
    "\n",
    "La vectorización es un concepto clave en el ámbito de la ciencia de datos y la programación computacional que sirve como un elemento fundamental para el manejo eficiente de datos en bibliotecas como Pandas. La idea se refiere fundamentalmente a la capacidad de realizar operaciones en conjuntos completos de datos, en lugar de iterar a través de cada elemento de manera individual.\n",
    "\n",
    "Este enfoque optimizado proporciona un rendimiento más eficiente al procesar grandes conjuntos de datos, ya que aprovecha las operaciones vectoriales implementadas en bibliotecas como NumPy y Pandas. En lugar de ejecutar operaciones en cada elemento de forma secuencial, la vectorización permite realizar cálculos en bloques de datos de manera simultánea, mejorando significativamente la velocidad de ejecución.\n",
    "\n",
    "En el contexto de Pandas, la vectorización permite realizar operaciones aritméticas, de comparación y aplicar funciones universales (ufuncs) a nivel de DataFrame o Serie de manera eficiente. Esta capacidad es crucial para el análisis y la manipulación eficientes de grandes conjuntos de datos, ya que evita la necesidad de bucles explícitos y facilita la escritura de código más conciso y legible. En resumen, la vectorización es una herramienta esencial que contribuye a la eficiencia y capacidad de procesamiento en la manipulación de datos en entornos de ciencia de datos y programación computacional.\n",
    "\n",
    "Ver:\n",
    "* [What Is A Vectorized Operation In Pandas](https://vegibit.com/what-is-a-vectorized-operation-in-pandas/#the-concept-of-vectorization-a-general-overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randint(1, 100, size=100_000)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df_loop = df.copy()\n",
    "\n",
    "for row in range(df.shape[0]):\n",
    "    df_loop.iloc[row] = df_loop.iloc[row]**2\n",
    "\n",
    "print(\"Proceso por medio de un loop: \", time.time() - start_time, \"segundos\") # con 100_000 datos tarda aprox entre 23 y 30 segundos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "df_vect = df.copy()\n",
    "df_vect = df_vect**2\n",
    "\n",
    "print(\"Proceso por medio de un loop: \", time.time() - start_time, \"segundos\") # con 100_000 datos tarda aprox 0.0009 segundos...\n",
    "\n",
    "### el loop tardó unas 27.000 veces más que la opoeración vectorial!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df, df_loop, df_vect], axis = 1).sample(10) # se obtienen los mismos resultados en una mínima fracción de tiempo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
