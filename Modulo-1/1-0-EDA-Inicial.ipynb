{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Qué implica el Análisis Exploratorio de Datos?\n",
    "\n",
    "El Análisis Exploratorio de Datos (EDA, por sus siglas en inglés) es una práctica utilizada por científicos de datos para investigar y analizar conjuntos de datos, resumiendo sus características principales mediante métodos de visualización de datos. Su propósito radica en determinar la mejor manera de manipular los datos para obtener respuestas pertinentes, lo que posibilita la identificación de patrones, detección de anomalías, validación de hipótesis y comprobación de suposiciones.\n",
    "\n",
    "El EDA se emplea principalmente para explorar la información más allá de la modelización formal o las pruebas de hipótesis, lo que permite comprender mejor las variables en un conjunto de datos y las relaciones entre ellas. Esta práctica también facilita la evaluación de la idoneidad de las técnicas estadísticas consideradas para el análisis de datos. Inicialmente desarrolladas por el matemático estadounidense John Tukey en la década de 1970, las técnicas de EDA continúan siendo ampliamente utilizadas en el proceso de descubrimiento de datos en la actualidad.\n",
    "\n",
    "#### Importancia del Análisis Exploratorio\n",
    "\n",
    "El objetivo principal del EDA es explorar los datos antes de realizar suposiciones, lo que permite identificar errores evidentes, comprender los patrones presentes, detectar valores atípicos y descubrir relaciones interesantes entre las variables. Los científicos de datos utilizan el EDA para asegurarse de que los resultados obtenidos sean válidos y aplicables a las conclusiones y objetivos de negocio deseados. Además, ayuda a confirmar a las partes interesadas que se están planteando las preguntas correctas, al proporcionar respuestas sobre desviaciones estándar, variables categóricas e intervalos de confianza. Una vez finalizado el EDA y extraída la información útil, sus hallazgos pueden ser utilizados para análisis o modelado de datos más complejos, incluido el aprendizaje automático.\n",
    "\n",
    "#### Herramientas de Análisis Exploratorio de Datos\n",
    "\n",
    "Las herramientas de EDA ofrecen diversas funciones y técnicas estadísticas, entre las que se incluyen:\n",
    "\n",
    "- Técnicas de agrupación en clúster y reducción de dimensiones, para crear visualizaciones de datos con múltiples variables.\n",
    "- Visualización univariante, que proporciona estadísticas de resumen de cada campo en el conjunto de datos.\n",
    "- Visualización bivariante, que evalúa la relación entre cada variable del conjunto de datos y la variable objetivo.\n",
    "- Visualización multivariante, que ayuda a comprender las interacciones entre diferentes campos en los datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "El objetivo de este módulo es realizar una introducción a las técnicas de EDA mediante el análisis de un dataset, que posee información sobre los trabajadores del área de datos. Por ejemplo, datos acerca de salarios, años de experiencia, posición de trabajo, entre otros.\n",
    "\n",
    "Para ello importaremos las siguientes librerías de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('..\\data\\Modulo-1\\jobs_in_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis preliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede visualizar las primeras filas del dataset para corroborar que se cargó correctamente\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luego, se procede a ver las dimensiones del mismo y las columnas que posee\n",
    "\n",
    "print(f'Cantidad de columnas: {df.shape[1]}', f'Cantidad de filas: {df.shape[0]}', sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Las columnas del df son:', df.columns.tolist(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede obtener el tipo de dato de cada columna, es decir, determinar si son valores numéricos (int o float) o categóricos (object)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es de gran utilidad poder determinar la completitud de los datos: saber si existen datos faltantes y en qué columnas se encuentran\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es recomendable analizar las variables numéricas y categóricas de forma separada\n",
    "\n",
    "## Variables categóricas\n",
    "\n",
    "df.describe(exclude=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables numéricas\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por último, podemos analizar la cardinalidad de los datos\n",
    "\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicados\n",
    "\n",
    "Antes de realizar análisis de mayor complejidad es esencial revisar si existen datos repetidos en el dataset, es decir, ver si existen registros que, por ejemplo, fueron cargados más de una vez y que, por ende, podrían llegar a modificar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.duplicated().any():\n",
    "    print('Existen duplicados en el dataset')\n",
    "else:\n",
    "    print('No hay duplicados en el dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Filas datset CON duplicados: {df.shape[0]}')\n",
    "\n",
    "# Dropeo los duplicados\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(f'Filas datset SIN duplicados: {df.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Análisis de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 1\n",
    "\n",
    "En este primer caso se buscará analizar la distribución de muestras por año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 6))\n",
    "ax = plt.subplot()\n",
    "\n",
    "sns.barplot(x=df['work_year'].value_counts().index, y=df['work_year'].value_counts().values, color='#d41145', ax = ax)\n",
    "\n",
    "ax.set_xlabel('Año')\n",
    "ax.set_ylabel('Cantidad de registros')\n",
    "ax.set_title('Cantidad de registros por año')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 2\n",
    "\n",
    "Se analiza la distribución de salarios por año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20, 6))\n",
    "\n",
    "sns.kdeplot(data=df,x='salary_in_usd', hue= 'work_year', common_norm=False, palette=sns.color_palette('pastel'), cut = 0 , ax=ax[0])\n",
    "sns.kdeplot(data=df,x='salary_in_usd', hue= 'work_year', common_norm=False, cumulative=True, palette=sns.color_palette('pastel'), cut = 0 , ax=ax[1])\n",
    "\n",
    "ax[0].set_xlabel('Salario en USD')\n",
    "ax[0].set_title('Distribución Salarios según Año')\n",
    "\n",
    "ax[1].set_xlabel('Salario en USD')\n",
    "ax[1].set_ylabel('Densidad Acumulada')\n",
    "ax[1].set_title('Distribución Salarios según Año')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 3\n",
    "\n",
    "Análisis más detallado de los salarios del año 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023 = df[df['work_year']==2023].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(20, 6))\n",
    "ax, ax2 = axes.flatten()\n",
    "\n",
    "#######################\n",
    "# Gráfico izquierda\n",
    "#######################\n",
    "\n",
    "sns.histplot(data=df_2023, x='salary_in_usd', cumulative=True, fill=False, element='step', stat='percent',bins=100, ax=ax)\n",
    "\n",
    "ax.set_xlim(0, df_2023.salary_in_usd.max())\n",
    "\n",
    "for n, quant_tuple in enumerate(dict(df_2023.salary_in_usd.quantile([0.25, 0.5, 0.75, 0.90, 0.95])).items()):\n",
    "\n",
    "    quant = quant_tuple[0] * 100\n",
    "    value = quant_tuple[1]\n",
    "\n",
    "    ax.scatter(value, quant, s=16, c=sns.color_palette('bright')[n], zorder = 20, label=f'Percentil {int(quant)}')\n",
    "    ax.plot((0, value), (quant, quant), c=sns.color_palette('bright')[n], linestyle='--', alpha=0.4)\n",
    "    ax.plot((value, value), (0, quant), c=sns.color_palette('bright')[n], linestyle='--', alpha=0.4)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title('CDF y Percentiles')\n",
    "\n",
    "#######################\n",
    "# Gráfico derecha\n",
    "#######################\n",
    "\n",
    "sns.boxplot(data=df_2023, x='salary_in_usd', saturation=0.75, ax=ax2)\n",
    "ax2.set_title('Boxplot')\n",
    "\n",
    "plt.suptitle('Análisis Salarios 2023')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Caso 4:\n",
    "\n",
    "Análisis de los puestos de trabajo, nivel de experiencia y tamaño de la empresa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es posible ver la proporción de trabajadores en cada tipo de empresa\n",
    "(df.groupby(by = ['company_size'])['job_title'].size() / df.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es posible ver la cantidad de trabajadores en cada tipo de empresa según su experiencia laboral\n",
    "\n",
    "df.groupby(by = ['company_size', 'experience_level']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# además, se analiza su salario\n",
    "df.groupby(by = ['company_size', 'experience_level']).agg({'salary_in_usd': ['mean', 'max', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puede ser de interés determinar si existe alguna diferencia entre los salarios de los trabajadores 'in-person', 'hybrid' y 'remote'\n",
    "\n",
    "df.groupby(by = ['company_size', 'experience_level', 'work_setting']).agg({'salary_in_usd': ['mean', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "work_settings = df['work_setting'].unique()\n",
    "\n",
    "for i in range(ax.shape[0]):\n",
    "\n",
    "    sns.histplot(data=df[df['work_setting']==work_settings[i]], x='salary_in_usd', stat='percent',bins=25, alpha=0.30, color=sns.color_palette('pastel')[i],  ax=ax[i])\n",
    "\n",
    "    ax_twin = ax[i].twinx()\n",
    "    sns.histplot(data=df[df['work_setting']==work_settings[i]], x='salary_in_usd', stat='percent',\n",
    "                  cumulative=True, fill=False, element='step', bins=25, color=sns.color_palette('pastel')[i],\n",
    "                  ax=ax_twin)\n",
    "\n",
    "    # Set x-axis ticks y labels\n",
    "    ax[i].set_xbound(0)\n",
    "    x_ticks = ax[0].get_xticks() if len(ax[0].get_xticks()) < 5 else ax[0].get_xticks()[::int(len(ax[0].get_xticks()) / 5)]   \n",
    "    ax[i].set_xticks(x_ticks)\n",
    "\n",
    "    # Set y-axis label\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel('Porcentaje PDF')\n",
    "        ax_twin.set_ylabel('')\n",
    "    elif i == ax.shape[0] - 1:\n",
    "        ax[i].set_ylabel('')\n",
    "        ax_twin.set_ylabel('Porcentaje CDF')\n",
    "    else:\n",
    "        ax[i].set_ylabel('')\n",
    "        ax_twin.set_ylabel('')\n",
    "\n",
    "    ax[i].set_title(f'work_setting: {work_settings[i]}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso 5:\n",
    "\n",
    "Además de usar representaciones gráficas para comprender los datos de nuestro dataset se puede recurrir a extraer información por medio de *\"queries\"* o *consultas*.\n",
    "\n",
    "A modo de ejemplo, se intentará dar respuesta a una serie de consignas que se presentan a continuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta 1:\n",
    "\n",
    "¿ Cuántos *Data Architects* que no residen en Estados Unidos cobrán un salario mayor a 85.000 usd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df[(df['job_title']=='Data Architect') & (df['employee_residence']!='United States') & (df['salary_in_usd']>85_000)].shape[0]\n",
    "\n",
    "print(f'Los Data Architects que no trabajan en EEUU y que posee un sueldo mayor a 85.000 usd son {res}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df['job_title']=='Data Architect' --> filtra el dataset para obtener solo los registros con 'job_title' igual a 'Data Architect'\n",
    "\n",
    "& --> es la condición 'Y'\n",
    "\n",
    "df['employee_residence']!='United States' --> filtra el dataset para obtener solo los registros con 'employee_residence' igual a 'United States'\n",
    "\n",
    "& --> es la condición 'Y'\n",
    "\n",
    "df['salary_in_usd']>85_000 --> filtra el dataset para obtener solo los registros con 'salary_in_usd' igual a 85_000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta 2:\n",
    "\n",
    "¿Cuál es el trabajo ('job_title') más popular en Argentina, EEUU, Alemania y Brasil?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df[df['employee_residence'].isin(['Argentina', 'Brazil', 'United States', 'Germany'])].groupby(by=['employee_residence'])['job_title'].agg(lambda x: x.mode())).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df['employee_residence'].isin(['Argentina', 'Brazil', 'United States', 'Germany']) --> filtra los registros para obtener solo auqellos que están en la lista\n",
    "\n",
    ".groupby(by=['employee_residence']) --> agrupo los datos por país de residencia de los empleados\n",
    "\n",
    "['job_title'].agg(lambda x: x.mode()) --> calculo la moda, es decir, el valor más frecuente, de la columna especificada\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta 3:\n",
    "\n",
    "Dentro de los sueldos que se encuentran por encima del percentil 90 (inclusive), ¿cuál es la *job_category* más popular? ¿Cómo se distribuyen los valores de *experience_level*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forma 'manual' de obtener el percentil al que pertenece cada registro\n",
    "\n",
    "aux = pd.DataFrame(df['salary_in_usd'].sort_values(ascending=True))\n",
    "\n",
    "aux['bin'] = np.nan\n",
    "\n",
    "q_bins = int(np.floor(aux.shape[0] / 10))\n",
    "for i in range(10):\n",
    "    aux.iloc[i * q_bins: (i+1) * q_bins, 1] = i\n",
    "\n",
    "aux = aux.fillna(i)\n",
    "\n",
    "df_aux = pd.concat([df, aux['bin']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrar solo los registros que se ubican a partir del percentil 90\n",
    "df_90 = df_aux[df_aux['bin']>=9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtener la categoría más popular de trabajo\n",
    "job_cat = df_90['job_category'].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en esa categoría, obtener las distrbución de la experiencia\n",
    "exp_dist = dict(df_90.loc[df_90['job_category']==job_cat, 'experience_level'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'La \"job_category\" más popular en los percentiles superiores al 90 es \"{job_cat}\".')\n",
    "\n",
    "for i, kv in enumerate(exp_dist.items()):\n",
    "    print(f'{i+1}) {kv[0]}: {kv[1]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta 4:\n",
    "\n",
    "¿Cuál es la 'job_category' cuyos 'Senior' cobran el menor sueldo **en promedio**? ¿Hay relación con la columna 'employee_residence'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['experience_level']=='Senior'].groupby(by=['job_category'])['salary_in_usd'].mean().idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['experience_level']=='Senior'].groupby(by=['job_category'])['salary_in_usd'].mean().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['experience_level']=='Senior') & (df['job_category'].isin(['Data Management and Strategy', 'Machine Learning and AI']))]\\\n",
    "    .groupby(by='job_category')['employee_residence'].value_counts(normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
